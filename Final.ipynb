{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into train and test sets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.applications import DenseNet121\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define your dataset directory\n",
    "# Define paths\n",
    "dataset_dir = '/Users/sumlipuri/Desktop/plant_disease_detection-main/DataSet/color'  # Assuming your dataset is in this directory\n",
    "train_dir = 'PlantVillage_newDataset/train'\n",
    "test_dir = 'PlantVillage_newDataset/test'\n",
    "\n",
    "class_names = os.listdir(dataset_dir)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Create train and test directories\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Define ratio for train-test split\n",
    "train_ratio = 0.8  # 80% for training, 20% for testing\n",
    "\n",
    "# Iterate over each class directory\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    if os.path.isdir(class_dir):\n",
    "        # Create subdirectories in train and test directories\n",
    "        os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
    "        \n",
    "        # Get list of image files in class directory\n",
    "        image_files = os.listdir(class_dir)\n",
    "        # Shuffle the list of image files\n",
    "        random.shuffle(image_files)\n",
    "        \n",
    "        # Split the image files into train and test sets\n",
    "        num_train_samples = int(len(image_files) * train_ratio)\n",
    "        train_images = image_files[:num_train_samples]\n",
    "        test_images = image_files[num_train_samples:]\n",
    "        \n",
    "        # Copy train images to train directory\n",
    "        for image_name in train_images:\n",
    "            src = os.path.join(class_dir, image_name)\n",
    "            dst = os.path.join(train_dir, class_name, image_name)\n",
    "            shutil.copyfile(src, dst)\n",
    "        \n",
    "        # Copy test images to test directory\n",
    "        for image_name in test_images:\n",
    "            src = os.path.join(class_dir, image_name)\n",
    "            dst = os.path.join(test_dir, class_name, image_name)\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "print(\"Dataset split into train and test sets.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43456 images belonging to 38 classes.\n",
      "Found 10849 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/Users/sumlipuri/Desktop/plant_disease_detection-main/DataSet/color'  # Assuming your dataset is in this directory\n",
    "\n",
    "# test_data_gen = ImageDataGenerator(rescale=1./255, validation_split=.2)\n",
    "# train_data_gen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest')\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# # Load data\n",
    "# train_data = train_datagen.flow_from_directory(\n",
    "#     directory=dataset_dir,\n",
    "#     target_size=(256, 256),\n",
    "#     batch_size=32,\n",
    "#     class_mode='categorical')\n",
    "\n",
    "# test_data = test_data_gen.flow_from_directory(\n",
    "#     directory=dataset_dir,\n",
    "#     target_size=(256, 256),\n",
    "#     batch_size=32,\n",
    "#     class_mode='categorical')\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    validation_split = 0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52155 images belonging to 38 classes.\n",
      "Found 19602 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load pre-trained DenseNet121 model\n",
    "model_d = DenseNet121(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Add custom layers on top of the pre-trained model\n",
    "x = model_d.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "preds = Dense(2, activation='softmax')(x) #change with number of classes\n",
    "\n",
    "# Combine pre-trained model and custom layers\n",
    "model = Model(inputs=model_d.input, outputs=preds)\n",
    "\n",
    "# Freeze pre-trained layers for initial training\n",
    "for layer in model_d.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load data\n",
    "train_data = train_data_gen.flow_from_directory(\n",
    "    directory=\"Users/sumlipuri/Desktop/plant_disease_detection-main/PlantVillage_newDataset/train/\",\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_data = test_data_gen.flow_from_directory(\n",
    "    directory=\"Users/sumlipuri/Desktop/plant_disease_detection-main/PlantVillage_newDataset/test/\",\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"keras/models.keras\",\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto')\n",
    "\n",
    "early = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('/Users/sumlipuri/Desktop/plant_disease_detection-main/plant_village_denseNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 1770s 3s/step - loss: 0.0223 - accuracy: 0.9928\n",
      "Test set accuracy: 99.28068518638611\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(test_data)\n",
    "print('Test set accuracy:', accuracy[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 1626s 3s/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.02      0.02       230\n",
      "           1       0.00      0.00      0.00       224\n",
      "           2       0.00      0.00      0.00        97\n",
      "           3       0.04      0.04      0.04       593\n",
      "           4       0.03      0.03      0.03       533\n",
      "           5       0.02      0.02      0.02       378\n",
      "           6       0.01      0.01      0.01       312\n",
      "           7       0.01      0.01      0.01       181\n",
      "           8       0.01      0.01      0.01       441\n",
      "           9       0.01      0.01      0.01       345\n",
      "          10       0.02      0.02      0.02       417\n",
      "          11       0.03      0.03      0.03       428\n",
      "          12       0.02      0.02      0.02       500\n",
      "          13       0.02      0.02      0.02       392\n",
      "          14       0.00      0.00      0.00       151\n",
      "          15       0.11      0.11      0.11      1995\n",
      "          16       0.05      0.05      0.05       825\n",
      "          17       0.00      0.00      0.00       132\n",
      "          18       0.02      0.02      0.02       365\n",
      "          19       0.02      0.02      0.02       523\n",
      "          20       0.03      0.03      0.03       351\n",
      "          21       0.01      0.01      0.01       362\n",
      "          22       0.00      0.00      0.00        55\n",
      "          23       0.01      0.01      0.01       138\n",
      "          24       0.10      0.10      0.10      1826\n",
      "          25       0.03      0.03      0.03       660\n",
      "          26       0.01      0.01      0.01       404\n",
      "          27       0.00      0.00      0.00       162\n",
      "          28       0.04      0.04      0.04       767\n",
      "          29       0.01      0.01      0.01       363\n",
      "          30       0.03      0.03      0.03       689\n",
      "          31       0.03      0.03      0.03       353\n",
      "          32       0.02      0.02      0.02       633\n",
      "          33       0.05      0.05      0.05       613\n",
      "          34       0.02      0.02      0.02       502\n",
      "          35       0.10      0.10      0.10      1949\n",
      "          36       0.00      0.00      0.00       134\n",
      "          37       0.03      0.03      0.03       579\n",
      "\n",
      "    accuracy                           0.05     19602\n",
      "   macro avg       0.02      0.02      0.02     19602\n",
      "weighted avg       0.05      0.05      0.05     19602\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  4   1   4 ...  25   1   9]\n",
      " [  3   0   0 ...  24   0   5]\n",
      " [  0   1   0 ...  12   0   5]\n",
      " ...\n",
      " [ 21  14   9 ... 193  12  53]\n",
      " [  3   1   1 ...  13   0   5]\n",
      " [ 11   4   2 ...  51   5  16]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_true = test_data.classes\n",
    "y_pred = np.argmax(model.predict(test_data), axis=1)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4   1   4 ...  25   1   9]\n",
      " [  3   0   0 ...  24   0   5]\n",
      " [  0   1   0 ...  12   0   5]\n",
      " ...\n",
      " [ 21  14   9 ... 193  12  53]\n",
      " [  3   1   1 ...  13   0   5]\n",
      " [ 11   4   2 ...  51   5  16]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "filename = \"D:/VSCode/AI & ML Project/Dataset/Apple/Apple___Apple_scab/0a5e9323-dbad-432d-ac58-d291718345d9___FREC_Scab 3417.JPG\"\n",
    "# AI & ML Project/Dataset/Tomato/Tomato___Bacterial_spot/00a7c269-3476-4d25-b744-44d6353cd921___GCREC_Bact.Sp 5807.JPG\n",
    "# AI & ML Project/Dataset/Apple/Apple___Apple_scab/0a5e9323-dbad-432d-ac58-d291718345d9___FREC_Scab 3417.JPG\n",
    "def process_image(image_path):\n",
    "    # Load and preprocess the image for your model\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((256, 256))  # adjust the size according to your model's input\n",
    "    img_array = np.array(img) / 255.0  # normalize pixel values\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # add batch dimension\n",
    "    return img_array\n",
    "\n",
    "img_array = process_image(filename)\n",
    "batch_prediction= model.predict(img_array)\n",
    "print(\"Predicted Disease\",class_names[np.argmax(batch_prediction[0])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
